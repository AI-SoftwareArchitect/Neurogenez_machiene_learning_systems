ğŸ§  GrowNet: Dynamic Neuron Growth in Deep Learning
Welcome to the GrowNet project! ğŸš€ This project explores a new approach to deep learning, where the neural network's architecture grows during training by adding new neurons to the hidden layers. It's like giving your model a brain boost every epoch! ğŸ§ ğŸ’¡

ğŸš€ What's this about?
We start with a small neural network, train it on the MNIST dataset ğŸ§‘â€ğŸ«, and after each epoch, we expand the number of neurons in the hidden layers.

The idea? Mimic the biological brain's ability to grow and adapt over time! ğŸŒ±

ğŸ“š Features
Dynamic neuron growth during training ğŸŒ±

Progressive increase in model complexity as training continues ğŸ§ 

Built using PyTorch ğŸ”¥

Performance improvement as more neurons are added! ğŸ¯

ğŸ“Š Model Architecture
Layer	Input Size	Output Size	Growth per Epoch
Input Layer	28x28 (784)	784	N/A
Hidden Layer	784	64 â†’ 104	+8 neurons/epoch
Output Layer	64 â†’ 104	10 (digits)	N/A
Input Layer: Takes the MNIST image (28x28 pixels).

Hidden Layer: Grows with +8 neurons after each epoch.

Output Layer: Classifies into 10 possible digit classes (0-9).

ğŸ› ï¸ How it Works?
GrowLinear Layer: Custom layer that allows neurons to grow by adding new ones at the end of training epochs.

Neural Growth: After each epoch, the model's neurons grow! ğŸ‰ Each growth round adds new neurons to the hidden layer, increasing model capacity.

Training: The model trains using MNIST data, which is a dataset of handwritten digits.

ğŸ“ˆ Performance
The model improves progressively over time as the neurons grow! Hereâ€™s a quick look at how it evolved:

Epoch	Accuracy	Hidden Layer Size	Neurons Added
1	89.57%	72	+8
2	94.20%	80	+8
3	94.24%	88	+8
4	94.26%	96	+8
5	94.26%	104	+8
Each epoch, we grow a bit more! ğŸŒ± By the end, the model has significantly improved accuracy. ğŸŒŸ

ğŸ” Confusion Matrix
Hereâ€™s how the model performed across different digits! The confusion matrix shows us where the model did well (diagonal) and where it struggled (off-diagonal). ğŸ“Š


ğŸ’» Installation and Setup
To run the project, you'll need the following libraries:

PyTorch (for neural network magic ğŸ§™â€â™‚ï¸)

TorchVision (for the MNIST dataset ğŸ“š)

Seaborn (for visualizing confusion matrix ğŸ“ˆ)

Clone this repository:

bash
Kopyala
DÃ¼zenle
git clone https://github.com/your-username/grownet.git
cd grownet
Install dependencies:

bash
Kopyala
DÃ¼zenle
pip install -r requirements.txt
Run the model:

bash
Kopyala
DÃ¼zenle
python main.py
ğŸ”§ Dependencies
PyTorch

TorchVision

Seaborn

Matplotlib

ğŸ“¸ Visualization
Hereâ€™s a glimpse of how the confusion matrix looks after training. As you can see, the model starts classifying digits pretty well! The darker the shade, the more accurate the predictions. ğŸ’ª


ğŸ”® Future Enhancements
ğŸš€ Dynamic pruning of neurons: Only keep the best neurons for more efficient growth!

ğŸŒ Expand the model to handle other datasets like CIFAR-10 or ImageNet.

ğŸ§  Biologically inspired learning mechanisms like synaptic plasticity.

ğŸ‘¥ Contributing
Want to contribute? ğŸ‰ We welcome PRs to make the brain grow even smarter. Check the issues section for any open tasks!
